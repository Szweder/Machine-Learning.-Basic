{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNfx1uuPpT1I6gkSp77naeR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Домашнее задание 09: KNN и EDA\n","\n","В этом задании мы:\n","- исследуем датасет по раку груди (EDA),\n","- визуализируем данные и сделаем выводы,\n","- обучим модель kNN, проведем настройку параметров,\n","- дополнительно сравним с логистической регрессией.\n"],"metadata":{"id":"FdqFq_p31-ry"}},{"cell_type":"markdown","source":["## Импорт необходимых библиотек"],"metadata":{"id":"2_wfGyek64wj"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix, classification_report\n",")\n","from sklearn.linear_model import LogisticRegressionCV\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n"],"metadata":{"id":"zuiozY0X2Dfh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Загрузка и предварительный просмотр данных"],"metadata":{"id":"MDYLwZMG7BdS"}},{"cell_type":"code","source":["# Загрузка файла (убедитесь, что файл загружен в среду выполнения)\n","df = pd.read_csv(\"column_2C_weka-261623-2043cd.csv\")\n","df.head()"],"metadata":{"id":"DoF1ATce2Hoh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Описание признаков и целевой переменной\n","\n","В данном наборе данных представлены характеристики позвоночника человека.  \n","Каждая строка — измерения одного пациента.\n","\n","**Признаки:**\n","- `pelvic_incidence`\n","- `pelvic_tilt numeric`\n","- `lumbar_lordosis_angle`\n","- `sacral_slope`\n","- `pelvic_radius`\n","- `degree_spondylolisthesis`\n","\n","**Целевая переменная:**\n","- `class` — состояние позвоночника: `\"Normal\"` или `\"Abnormal\"`"],"metadata":{"id":"rlnwb48E7J86"}},{"cell_type":"markdown","source":["## Описательная статистика и проверка типов данных"],"metadata":{"id":"2Ur98bq27XBi"}},{"cell_type":"code","source":["# Проверим общую информацию\n","df.info()"],"metadata":{"id":"V7NxRvTI7X2G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Основные статистики по числовым столбцам\n","df.describe()"],"metadata":{"id":"lcVQ7AxN7b4C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Проверим, какие уникальные значения принимает целевая переменная\n","df['class'].value_counts()"],"metadata":{"id":"pg2ylQnH7eEh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Визуализация распределений признаков\n","\n","Для каждого признака построим гистограммы, разделив по классам.\n"],"metadata":{"id":"ZdRGds6N7ZWh"}},{"cell_type":"code","source":["# Список признаков (без целевой переменной)\n","features = df.columns[:-1]\n","\n","# Построим распределения\n","plt.figure(figsize=(16, 12))\n","for i, feature in enumerate(features, 1):\n","    plt.subplot(3, 2, i)\n","    sns.histplot(data=df, x=feature, hue='class', kde=True, element=\"step\", stat=\"density\", common_norm=False)\n","    plt.title(f'Распределение признака: {feature}')\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"kCEC1uV17i16"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Матрица корреляции и тепловая карта\n","\n","Исследуем корреляции между признаками. Это поможет выявить линейно зависимые переменные.\n"],"metadata":{"id":"EGEpfCMj7lS5"}},{"cell_type":"code","source":["# Матрица корреляции\n","corr_matrix = df[features].corr()\n","\n","# Визуализация тепловой карты\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n","plt.title('Корреляционная матрица признаков')\n","plt.show()\n"],"metadata":{"id":"KtEiKVsZ7naT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Попарные scatterplot-графики для сильно коррелированных признаков\n","\n","Построим scatterplot для пар признаков, между которыми наблюдается высокая корреляция (по модулю выше 0.85).\n"],"metadata":{"id":"F12gcK-d70xC"}},{"cell_type":"code","source":["# Найдём пары сильно коррелированных признаков\n","high_corr = []\n","threshold = 0.85\n","for i in range(len(corr_matrix.columns)):\n","    for j in range(i + 1, len(corr_matrix.columns)):\n","        if abs(corr_matrix.iloc[i, j]) > threshold:\n","            high_corr.append((corr_matrix.columns[i], corr_matrix.columns[j]))\n","\n","# Построим scatterplot'ы\n","for x, y in high_corr:\n","    sns.lmplot(data=df, x=x, y=y, hue=\"class\", aspect=1.3, height=5, fit_reg=True)\n","    plt.title(f'Scatterplot: {x} vs {y}')\n","    plt.show()\n"],"metadata":{"id":"Q46eqQXJ73lC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Boxplot-графики для выявления информативных признаков\n","\n","С помощью boxplot-графиков определим, какие признаки лучше всего разделяют классы.\n"],"metadata":{"id":"4V7m_pYB79eL"}},{"cell_type":"code","source":["# Построим boxplot-графики\n","plt.figure(figsize=(16, 12))\n","for i, feature in enumerate(features, 1):\n","    plt.subplot(3, 2, i)\n","    sns.boxplot(x='class', y=feature, data=df)\n","    plt.title(f'Boxplot: {feature}')\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"elLmAo3k8AB7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Выводы по результатам EDA\n","\n","- Некоторые признаки (например, `pelvic_incidence`, `sacral_slope`) демонстрируют хорошее разделение между классами.\n","- Между `pelvic_incidence` и `sacral_slope` наблюдается высокая положительная корреляция.\n","- Распределения некоторых признаков различаются между классами, что важно для классификации.\n","- Корреляционная матрица выявила несколько пар зависимых признаков, это стоит учесть при моделировании.\n"],"metadata":{"id":"pBDvEaUG8B5a"}},{"cell_type":"markdown","source":["## Часть 2: Построение модели kNN\n","\n","Теперь приступим к построению модели:\n","- Разделим данные на обучающую и тестовую выборки.\n","- Приведем признаки к одному масштабу с помощью стандартизации.\n","- Обучим модель kNN и оценим её качество.\n"],"metadata":{"id":"zi2gibIB8H6q"}},{"cell_type":"code","source":["# Разделим на признаки и целевую переменную\n","X = df[features]\n","y = df['class']\n","\n","# Разделение на train/test\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.3, random_state=42, stratify=y\n",")\n","\n","print(\"Train shape:\", X_train.shape)\n","print(\"Test shape:\", X_test.shape)\n"],"metadata":{"id":"uO1Dwlhq8JxK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Стандартизация данных\n","\n","Нормализация важна для корректной работы kNN, т.к. алгоритм чувствителен к масштабу признаков. Мы применим `StandardScaler` для приведения признаков к одному масштабу.\n"],"metadata":{"id":"3W3vTkMU8LiC"}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n"],"metadata":{"id":"XyVn7Umn8NRy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Обучение модели kNN\n","\n","Обучим модель kNN с параметрами по умолчанию и оценим качество классификации.\n"],"metadata":{"id":"ShLk-DeN8PyS"}},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n","\n","# Инициализация модели\n","knn = KNeighborsClassifier()\n","knn.fit(X_train_scaled, y_train)\n","\n","# Предсказание\n","y_pred = knn.predict(X_test_scaled)\n","y_proba = knn.predict_proba(X_test_scaled)[:, 1]\n","\n","# Оценка\n","print(classification_report(y_test, y_pred))\n"],"metadata":{"id":"P8XIHutc8VzK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ROC-кривая\n","fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n","auc = roc_auc_score(y_test, y_proba)\n","\n","plt.figure(figsize=(6, 4))\n","plt.plot(fpr, tpr, label=f'kNN ROC AUC = {auc:.2f}')\n","plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC-кривая для kNN')\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"d_llzm398X_y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Настройка параметра k (число соседей) с помощью кросс-валидации\n","\n","Мы протестируем разные значения `k` от 1 до 20 и выберем то, при котором точность на валидации будет максимальной.\n"],"metadata":{"id":"rrLNDEbK8hkS"}},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_score\n","\n","# Тестируем k от 1 до 20\n","k_range = range(1, 21)\n","cv_scores = []\n","\n","for k in k_range:\n","    knn = KNeighborsClassifier(n_neighbors=k)\n","    scores = cross_val_score(knn, X_train_scaled, y_train, cv=5, scoring='accuracy')\n","    cv_scores.append(scores.mean())\n","\n","# Визуализируем\n","plt.figure(figsize=(8, 4))\n","plt.plot(k_range, cv_scores, marker='o')\n","plt.xlabel('k (количество соседей)')\n","plt.ylabel('Средняя точность (cross-val)')\n","plt.title('Выбор оптимального k по кросс-валидации')\n","plt.grid(True)\n","plt.show()\n"],"metadata":{"id":"kFa0W2s28nbi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Оптимальное значение k\n","optimal_k = k_range[cv_scores.index(max(cv_scores))]\n","print(f\"Оптимальное значение k: {optimal_k}\")\n"],"metadata":{"id":"njwSPjCw83DS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Финальное обучение модели с оптимальным k\n"],"metadata":{"id":"eBEZGKQW863i"}},{"cell_type":"code","source":["# Обучим модель с оптимальным k\n","best_knn = KNeighborsClassifier(n_neighbors=optimal_k)\n","best_knn.fit(X_train_scaled, y_train)\n","y_pred_best = best_knn.predict(X_test_scaled)\n","y_proba_best = best_knn.predict_proba(X_test_scaled)[:, 1]\n","\n","# Оценка качества\n","print(classification_report(y_test, y_pred_best))\n","\n","# ROC для лучшей модели\n","fpr, tpr, thresholds = roc_curve(y_test, y_proba_best)\n","auc = roc_auc_score(y_test, y_proba_best)\n","\n","plt.figure(figsize=(6, 4))\n","plt.plot(fpr, tpr, label=f'kNN (k={optimal_k}) ROC AUC = {auc:.2f}')\n","plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC-кривая для kNN (настроенный)')\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"xRwqv-TP9BQr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Бонус: Логистическая регрессия и сравнение с kNN\n","\n","Мы проверим, как логистическая регрессия справляется с задачей на тех же данных:\n","- удалим сильно коррелированные признаки (|r| > 0.85),\n","- обучим логистическую регрессию,\n","- сравним метрики качества с моделью kNN.\n"],"metadata":{"id":"SffdtNbg9KFq"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n","\n","# Сначала уберём признаки с сильной корреляцией\n","corr_matrix = df.iloc[:, 2:].corr().abs()\n","upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n","\n","to_drop = [column for column in upper.columns if any(upper[column] > 0.85)]\n","print(f\"Удаляем {len(to_drop)} признаков с высокой корреляцией:\\n{to_drop}\")\n"],"metadata":{"id":"RPH3zgTk9MwK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Новый датафрейм без сильно коррелированных признаков\n","X_reduced = df.drop(columns=to_drop + ['diagnosis', 'id'])\n","y = df['diagnosis'].map({'M': 1, 'B': 0})\n","\n","# Масштабируем и делим\n","X_train_red, X_test_red, y_train_red, y_test_red = train_test_split(X_reduced, y, test_size=0.3, random_state=42)\n","scaler = StandardScaler()\n","X_train_red_scaled = scaler.fit_transform(X_train_red)\n","X_test_red_scaled = scaler.transform(X_test_red)\n"],"metadata":{"id":"0kkV-Lq-9PHC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Обучение логистической регрессии «из коробки»\n"],"metadata":{"id":"4G9oxZFP9Q_S"}},{"cell_type":"code","source":["log_reg = LogisticRegression(max_iter=1000)\n","log_reg.fit(X_train_red_scaled, y_train_red)\n","\n","y_pred_lr = log_reg.predict(X_test_red_scaled)\n","y_proba_lr = log_reg.predict_proba(X_test_red_scaled)[:, 1]\n","\n","print(classification_report(y_test_red := y_test_red if 'y_test_red' in locals() else y_test, y_pred_lr))\n"],"metadata":{"id":"gl0WDEAh9TXC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ROC-кривая и AUC для логистической регрессии\n"],"metadata":{"id":"gBDFJmsj9WCr"}},{"cell_type":"code","source":["fpr_lr, tpr_lr, _ = roc_curve(y_test_red, y_proba_lr)\n","auc_lr = roc_auc_score(y_test_red, y_proba_lr)\n","\n","plt.figure(figsize=(6, 4))\n","plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression ROC AUC = {auc_lr:.2f}')\n","plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC-кривая для логистической регрессии')\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"yIDNi0eT9a5y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Настройка логистической регрессии (LogisticRegressionCV)\n"],"metadata":{"id":"YB-616bL9dEy"}},{"cell_type":"code","source":["log_reg_cv = LogisticRegressionCV(cv=5, max_iter=1000)\n","log_reg_cv.fit(X_train_red_scaled, y_train_red)\n","\n","y_pred_cv = log_reg_cv.predict(X_test_red_scaled)\n","y_proba_cv = log_reg_cv.predict_proba(X_test_red_scaled)[:, 1]\n","\n","print(classification_report(y_test_red, y_pred_cv))\n"],"metadata":{"id":"M2qQkuoj9gDK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Сравнение моделей: логистическая регрессия против kNN\n","\n","- kNN лучше работает с небольшими, простыми датасетами.\n","- Логистическая регрессия более интерпретируема и устойчива к переобучению.\n","- Настроенная логистическая регрессия показала следующие результаты...\n"],"metadata":{"id":"UPq4q_ML9j5S"}}]}